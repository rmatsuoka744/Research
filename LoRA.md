# **[LoRA(Low-Rank Adaptation)](https://arxiv.org/pdf/2106.09685.pdf)**

# **LoRAとは何か**
LoRAは、大規模な言語モデルの効率的なファインチューニングを可能にする手法です。従来のファインチューニング手法では、大規模言語モデルの膨大なパラメータを、専門的なデータセットを用いて更新することでモデルを調整していました。この方法は、多くの時間とコストを要するという問題点がありました。

LoRAでは、元のモデルのパラメータは凍結され、更新されません。代わりに、学習可能な低ランク行列をTransformer層に挿入することで、従来のファインチューニングよりも速く、コストも低く調整を行うことができます。

LoRAのメリットとしては、元のモデルのパラメータを保持するため、異なる低ランク行列（Adapter）を取り付けることで、簡単に異なるタスクに対応したモデルを使い分けることができます。また、元のモデルを変更していないため、元々の言語能力を保ちつつ新たなタスクに適応できるという利点があります。

最近のトレンドとして、膨大なパラメータを持つモデルを知識蒸留によって軽量化・高速化した「蒸留モデル」に対して、LoRAを用いて迅速なファインチューニングを行う方法が注目されています。

# **LoRAの基本概念**
LoRAは、大規模な事前学習された言語モデル（例えば、GPT-3やBERTなど）をカスタマイズする新しい方法です。この方法は、モデル全体をファインチューニングする代わりに、モデルの一部分だけを微調整することに焦点を当てています。具体的には、モデルの特定の層に低ランク行列（Low-Rank Matrix）を追加し、それらを学習させることでモデルの挙動を変更します。

# **仕組み**
![](https://res.cloudinary.com/zenn/image/fetch/s--xZbYxavx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_1200/https://storage.googleapis.com/zenn-user-upload/deployed-images/cf37170994a94dd89104472a.png%3Fsha%3D3f5710ba0d3fda28301a88faf751bb49a5d2ffd4)  
- **基本概念**  
    言語モデルにはTransformer層と呼ばれる学習可能な重み行列を持つ層が存在しています。ここでは、図のように(d,d)の重み行列を持つとします。通常のファインチューニングであれば(d,d)行列の持つパラメータd^2個をすべて再調整しますが、LoRAでは図の右側のように、(d,r)と(r,d)行列の二つのパラメータ2dr個を調整します。この際、rはdよりはるかに小さい値であり、rをランクと呼びます。
- **低ランク行列**  
    図のように、W,A,Bの3つの行列を表すとします。この際、AとBの行列積は(d,d)行列となります。このように、巨大な行列Wを行列A,Bの積として分解することで、更新パラメータ数を大幅に削減することが可能です。
- **分解のメカニズム**  
    この手法では、元の(d,d)行列Wを調整する代わりに、(d,r),(r,d)のA,B行列をトレーニングします。A,B行列は損失を計算する際に行列積をとり(d,d)行列となり、これはWの変化量を近似します。学習の際はこの2つの行列のみが更新の対象となるため、元の重み行列Wは保持されます。

# **従来のファインチューニングとの相違点**
従来のファインチューニングでは、モデルの全パラメータを特定のタスクに合わせて再学習します。これに対して、LoRAでは以下の点が異なります：

- パラメータ数: LoRAは、既存のパラメータを直接変更するのではなく、追加のパラメータ（低ランク行列）を使用します。これにより、必要なパラメータ数が大幅に減少します。
- 効率: LoRAは、特定の層にのみ焦点を当てるため、計算効率が良く、トレーニング時間が短縮されます。

# **メリット**
- 効率性: LoRAは、従来のファインチューニングよりもはるかに高速で、計算資源を少なく消費します。
- 柔軟性: 異なるタスクやドメインに対して、小さな追加パラメータを使ってモデルをカスタマイズできます。
- 一般化性: LoRAは、大規模なモデルの一般化能力を損なうことなく、特定のタスクに対するパフォーマンスを向上させます。

# **デメリット**
- 制限されたカスタマイズ: LoRAは、モデルの特定の部分のみを調整するため、従来のファインチューニングほど深いレベルでのカスタマイズはできません。
- 専門知識の必要性: LoRAを効果的に使用するには、どの層を調整すべきか、どのように調整すべきかといった知識が必要です。

# **結論**
LoRAは、大規模な言語モデルのカスタマイズにおいて効率性と柔軟性を提供します。これにより、計算資源が限られている場合や、迅速なプロトタイピングが必要な場合に特に有用です。ただし、従来のファインチューニングに比べると、カスタマイズの自由度はやや制限されます。


